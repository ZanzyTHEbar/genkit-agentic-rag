package providers

import (
	"context"
	"fmt"
	"log/slog"
	"strings"
	"time"

	"github.com/ZanzyTHEbar/genkithandler/errors"

	"github.com/firebase/genkit/go/ai"
	"github.com/firebase/genkit/go/genkit"
	"github.com/firebase/genkit/go/plugins/googlegenai"
)

// RetryConfig defines retry behavior for API calls
type RetryConfig struct {
	MaxRetries int
	BaseDelay  time.Duration
	MaxDelay   time.Duration
}

type GoogleAIProviderConfig struct {
	pluginConfig config.GenkitPlugin
	// MaxOutputTokens is the maximum number of tokens to generate.
	// MaxOutputTokens int `json:"maxOutputTokens,omitempty"`
	// StopSequences is the list of sequences where the model will stop generating further tokens.
	// StopSequences []string `json:"stopSequences,omitempty"`
	// Temperature is the temperature to use for the model.
	// Temperature float64 `json:"temperature,omitempty"`
	// TopK is the number of top tokens to consider for the model.
	// TopK int `json:"topK,omitempty"`
	// TopP is the top-p value to use for the model.
	// TopP float64 `json:"topP,omitempty"`
	// Version is the version of the model to use.
	// Version string `json:"version,omitempty"`
	// SafetySettings is the list of safety settings to use for the model.
	// SafetySettings []*SafetySetting `json:"safetySettings,omitempty"`
	// CodeExecution is whether to allow executing of code generated by the model.
	// CodeExecution bool `json:"codeExecution,omitempty"`
	// Response modalities for returned model messages
	// ResponseModalities []Modality `json:"responseModalities,omitempty"`
	// Thinking configuration controls the model's internal reasoning process
	// ThinkingConfig *ThinkingConfig `json:"thinkingConfig,omitempty"`
	GeminiConfig googlegenai.GeminiConfig
}

// GoogleAIProvider represents the Google AI provider configuration using Genkit's built-in plugin
type GoogleAIProvider struct {
	initialized bool
	retryConfig RetryConfig
	config      GoogleAIProviderConfig
}

// NewGoogleAIProvider creates a new Google AI provider instance
func NewGoogleAIProvider(pluginCfg config.GenkitPlugin) *GoogleAIProvider {
	// Default retry configuration
	retryConfig := RetryConfig{
		MaxRetries: 3,
		BaseDelay:  1 * time.Second,
		MaxDelay:   30 * time.Second,
	}

	config := GoogleAIProviderConfig{
		pluginConfig: pluginCfg,
		GeminiConfig: googlegenai.GeminiConfig{},
	}

	return &GoogleAIProvider{
		config:      config,
		retryConfig: retryConfig,
	}
}

// GetModel returns the configured model for Google AI
func (p *GoogleAIProvider) GetModel() string {
	if p.config.pluginConfig.DefaultModel == "" {
		return "gemini-2.5-pro"
	}
	return p.config.pluginConfig.DefaultModel
}

// GenerateText generates text using the Google AI provider
func (p *GoogleAIProvider) GenerateText(ctx context.Context, g *genkit.Genkit, prompt string) (string, error) {
	if !p.initialized {
		return "", errors.New("provider not initialized")
	}

	// Use the built-in Genkit generate function with the Google AI model
	response, err := p.withRetry(ctx, func() (string, error) {
		// Get the model reference from the plugin
		model := googlegenai.GoogleAIModel(g, p.GetModel())
		if model == nil {
			return "", fmt.Errorf("model %s not found or not registered", p.GetModel())
		}

		result, err := genkit.Generate(ctx, g,
			ai.WithModel(model),
			ai.WithPrompt(prompt),
			ai.WithConfig(&p.config.GeminiConfig),
		)

		if err != nil {
			return "", err
		}

		return result.Text(), nil
	})

	return response, err
}

// GenerateWithStructuredOutput generates text with structured output using the Google AI provider
func (p *GoogleAIProvider) GenerateWithStructuredOutput(ctx context.Context, g *genkit.Genkit, prompt string, outputType interface{}) (*ai.ModelResponse, error) {
	if !p.initialized {
		return nil, errors.New("provider not initialized")
	}

	// Use the built-in Genkit generate function with structured output
	return p.withRetryStructured(ctx, func() (*ai.ModelResponse, error) {
		// Get the model reference from the plugin
		model := googlegenai.GoogleAIModel(g, p.GetModel())
		if model == nil {
			return nil, fmt.Errorf("model %s not found or not registered", p.GetModel())
		}

		result, err := genkit.Generate(ctx, g,
			ai.WithModel(model),
			ai.WithPrompt(prompt),
			ai.WithOutputType(outputType),
		)

		return result, err
	})
}

// withRetry implements retry logic for text generation
func (p *GoogleAIProvider) withRetry(ctx context.Context, fn func() (string, error)) (string, error) {
	var lastErr error

	for attempt := 0; attempt <= p.retryConfig.MaxRetries; attempt++ {
		if attempt > 0 {
			// Calculate exponential backoff delay
			delay := min(p.retryConfig.BaseDelay*time.Duration(1<<(attempt-1)), p.retryConfig.MaxDelay)

			slog.Debug("Retrying Google AI request",
				"attempt", attempt,
				"delay", delay.String(),
				"last_error", lastErr.Error())

			select {
			case <-ctx.Done():
				return "", ctx.Err()
			case <-time.After(delay):
				// Continue with retry
			}
		}

		result, err := fn()
		if err == nil {
			return result, nil
		}

		lastErr = err

		// Check if error is retryable
		if !p.isRetryable(err) {
			break
		}
	}

	return "", fmt.Errorf("google AI request failed after %d attempts: %w", p.retryConfig.MaxRetries+1, lastErr)
}

// withRetryStructured implements retry logic for structured generation
func (p *GoogleAIProvider) withRetryStructured(ctx context.Context, fn func() (*ai.ModelResponse, error)) (*ai.ModelResponse, error) {
	var lastErr error

	for attempt := 0; attempt <= p.retryConfig.MaxRetries; attempt++ {
		if attempt > 0 {
			// Calculate exponential backoff delay
			delay := min(p.retryConfig.BaseDelay*time.Duration(1<<(attempt-1)), p.retryConfig.MaxDelay)

			slog.Debug("Retrying Google AI structured request",
				"attempt", attempt,
				"delay", delay.String(),
				"last_error", lastErr.Error())

			select {
			case <-ctx.Done():
				return nil, ctx.Err()
			case <-time.After(delay):
				// Continue with retry
			}
		}

		result, err := fn()
		if err == nil {
			return result, nil
		}

		lastErr = err

		// Check if error is retryable
		if !p.isRetryable(err) {
			break
		}
	}

	return nil, fmt.Errorf("google AI structured request failed after %d attempts: %w", p.retryConfig.MaxRetries+1, lastErr)
}

// isRetryable determines if an error should trigger a retry
func (p *GoogleAIProvider) isRetryable(err error) bool {
	if err == nil {
		return false
	}

	errStr := strings.ToLower(err.Error())

	// Retryable conditions for Google AI API
	retryablePatterns := []string{
		"rate limit",
		"too many requests",
		"quota exceeded",
		"service unavailable",
		"internal error",
		"timeout",
		"connection reset",
		"temporary failure",
		"server error",
		"resource exhausted",
	}

	for _, pattern := range retryablePatterns {
		if strings.Contains(errStr, pattern) {
			return true
		}
	}

	return false
}

// IsAvailable checks if the Google AI provider is available and configured
func (p *GoogleAIProvider) IsAvailable() bool {
	return p.config.pluginConfig.APIKey != "" && p.initialized
}

// SupportsStructuredOutput indicates whether this provider supports structured output
func (p *GoogleAIProvider) SupportsStructuredOutput() bool {
	return true // Google AI/Gemini supports structured output
}

// GetMaxTokens returns the maximum token limit for the configured model
func (p *GoogleAIProvider) GetMaxTokens() int {
	// Return conservative limits for different Gemini models
	model := p.GetModel()
	switch model {
	case "gemini-2.5-pro", "gemini-2.5-pro-latest":
		return 2097152
	case "gemini-2.5-flash", "gemini-2.5-flash-latest":
		return 1048576
	case "gemini-2.0-flash":
		return 1048576
	default:
		return 32768
	}
}

// GenerateStream generates a streaming response (placeholder implementation)
func (p *GoogleAIProvider) GenerateStream(ctx context.Context, g *genkit.Genkit, prompt string) (<-chan StreamChunk, error) {
	if !p.initialized {
		resultChan := make(chan StreamChunk, 1)
		close(resultChan)
		return resultChan, errors.New("provider not initialized")
	}

	resultChan := make(chan StreamChunk, 10)

	// TODO: !!! Use Genkit's streaming capabilities when available !!!

	return resultChan, nil
}

// CallTool executes a tool through the AI model
func (p *GoogleAIProvider) CallTool(ctx context.Context, g *genkit.Genkit, toolName string, params map[string]interface{}) (*ToolCallResult, error) {
	if !p.initialized {
		return nil, errors.New("provider not initialized")
	}

	startTime := time.Now()

	// Validate inputs
	if toolName == "" {
		return &ToolCallResult{
			Result:   nil,
			Success:  false,
			Duration: time.Since(startTime),
			Error:    "tool name cannot be empty",
		}, fmt.Errorf("tool name cannot be empty")
	}

	// Create a prompt for tool calling
	toolPrompt := fmt.Sprintf("Execute tool '%s' with parameters: %v. Return the result in a structured format.", toolName, params)

	// Use the provider's text generation with retry logic
	response, err := p.withRetry(ctx, func() (string, error) {
		// Get the model reference from the plugin
		model := googlegenai.GoogleAIModel(g, p.GetModel())
		if model == nil {
			return "", fmt.Errorf("model %s not found or not registered", p.GetModel())
		}

		result, err := genkit.Generate(ctx, g,
			ai.WithModel(model),
			ai.WithPrompt(toolPrompt),
			ai.WithConfig(&p.config.GeminiConfig),
		)

		if err != nil {
			return "", err
		}

		return result.Text(), nil
	})

	duration := time.Since(startTime)

	if err != nil {
		return &ToolCallResult{
			Result:   nil,
			Success:  false,
			Duration: duration,
			Error:    err.Error(),
			Metadata: map[string]interface{}{
				"provider":   "googleai",
				"model":      p.GetModel(),
				"tool_name":  toolName,
				"error_type": "generation_failed",
			},
		}, err
	}

	// Create successful result
	result := &ToolCallResult{
		Result:   response,
		Success:  true,
		Duration: duration,
		Metadata: map[string]interface{}{
			"provider":     "googleai",
			"model":        p.GetModel(),
			"tool_name":    toolName,
			"prompt_used":  toolPrompt,
			"response_len": len(response),
		},
	}

	return result, nil
}
